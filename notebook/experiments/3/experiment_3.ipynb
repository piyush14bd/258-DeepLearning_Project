{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67fd5295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10f99e630>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXPERIMENT 3: Physics Formula Approximation\n",
    "# SHM: x(t) = A * cos(ω t)\n",
    "# Compare: MLP vs KAN (with and without auxiliary θ = ω t)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca013980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Train samples: 5000 | Test samples: 1000\n"
     ]
    }
   ],
   "source": [
    "# Genarate Synthetic Data\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def generate_shm_dataset(\n",
    "    n_samples=6000,\n",
    "    A_range=(0.5, 5.0),\n",
    "    w_range=(0.5, 10.0),\n",
    "    t_range=(0.0, 5.0),\n",
    "    noise_std=0.0,\n",
    "    device=device\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate samples of x(t) = A * cos(ω t) with optional Gaussian noise.\n",
    "    Returns:\n",
    "        A, w, t, x  (each of shape [N, 1], on CPU)\n",
    "    \"\"\"\n",
    "    A = torch.empty(n_samples, 1).uniform_(*A_range)\n",
    "    w = torch.empty(n_samples, 1).uniform_(*w_range)\n",
    "    t = torch.empty(n_samples, 1).uniform_(*t_range)\n",
    "\n",
    "    x = A * torch.cos(w * t)\n",
    "\n",
    "    if noise_std > 0:\n",
    "        x = x + noise_std * torch.randn_like(x)\n",
    "\n",
    "    return A, w, t, x\n",
    "\n",
    "# Generate data\n",
    "A, w, t, x = generate_shm_dataset(\n",
    "    n_samples=6000,\n",
    "    A_range=(0.5, 5.0),\n",
    "    w_range=(0.5, 10.0),\n",
    "    t_range=(0.0, 5.0),\n",
    "    noise_std=0.0,  # set >0 to test robustness\n",
    ")\n",
    "\n",
    "# Train / test split\n",
    "idx = torch.randperm(len(x))\n",
    "n_train = 5000\n",
    "train_idx = idx[:n_train]\n",
    "test_idx  = idx[n_train:]\n",
    "\n",
    "A_tr, w_tr, t_tr, x_tr = A[train_idx], w[train_idx], t[train_idx], x[train_idx]\n",
    "A_te, w_te, t_te, x_te = A[test_idx],  w[test_idx],  t[test_idx],  x[test_idx]\n",
    "\n",
    "# Push labels to device once\n",
    "y_tr = x_tr.to(device)\n",
    "y_te = x_te.to(device)\n",
    "\n",
    "print(\"Train samples:\", len(y_tr), \"| Test samples:\", len(y_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aac0042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Helper Metrics\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return torch.sqrt(nn.MSELoss()(y_pred, y_true)).item()\n",
    "\n",
    "def r2_score_torch(y_true, y_pred):\n",
    "    # y_* should be CPU numpy\n",
    "    return r2_score(y_true.detach().cpu().numpy(),\n",
    "                    y_pred.detach().cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe010bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "[MLP] epoch 50/200 | train_loss=4.417974\n",
      "[MLP] epoch 100/200 | train_loss=4.213521\n",
      "[MLP] epoch 150/200 | train_loss=4.057635\n",
      "[MLP] epoch 200/200 | train_loss=3.959777\n",
      "\n",
      "=== MLP baseline (A, ω, t) ===\n",
      "RMSE: 2.0393\n",
      "R²  : 0.1343\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# 3) MLP Baseline \n",
    "class SHMMLP(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden=64):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "mlp = SHMMLP().to(device)\n",
    "opt_mlp = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "Xtr_mlp = torch.cat([A_tr, w_tr, t_tr], dim=1).to(device)\n",
    "Xte_mlp = torch.cat([A_te, w_te, t_te], dim=1).to(device)\n",
    "\n",
    "EPOCHS_MLP = 200\n",
    "for ep in range(1, EPOCHS_MLP + 1):\n",
    "    mlp.train()\n",
    "    opt_mlp.zero_grad()\n",
    "    pred = mlp(Xtr_mlp)\n",
    "    loss = loss_fn(pred, y_tr)\n",
    "    loss.backward()\n",
    "    opt_mlp.step()\n",
    "    if ep % 50 == 0:\n",
    "        print(f\"[MLP] epoch {ep}/{EPOCHS_MLP} | train_loss={loss.item():.6f}\")\n",
    "\n",
    "mlp.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat_mlp = mlp(Xte_mlp)\n",
    "\n",
    "mlp_rmse = rmse(y_te, y_hat_mlp)\n",
    "mlp_r2   = r2_score_torch(y_te, y_hat_mlp)\n",
    "\n",
    "print(\"\\n=== MLP baseline (A, ω, t) ===\")\n",
    "print(f\"RMSE: {mlp_rmse:.4f}\")\n",
    "print(f\"R²  : {mlp_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "774ec110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "\n",
      "Training KAN with auxiliary θ = ω t ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.46e+00 | test_loss: 1.54e+00 | reg: 0.00e+00 | : 100%|█| 80/80 [01:11<00:00,  1.11it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "\n",
      "=== KAN (with θ = ω t) ===\n",
      "RMSE: 1.5359\n",
      "R²  : 0.5090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4 KAN Experiments\n",
    "import os\n",
    "os.environ.pop(\"MPLBACKEND\", None)  \n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")              \n",
    "\n",
    "import torch\n",
    "import kan\n",
    "\n",
    "try:\n",
    "    #KAN class is directly under kan\n",
    "    KAN = kan.KAN\n",
    "except AttributeError:\n",
    "    try:\n",
    "        # kan.KAN is a module that contains the class KAN\n",
    "        KAN = kan.KAN.KAN\n",
    "    except AttributeError:\n",
    "        # Fallback\n",
    "        from kan.MultKAN import MultKAN as KAN\n",
    "\n",
    "# θ = ω t\n",
    "theta_tr = (w_tr * t_tr).to(device)\n",
    "theta_te = (w_te * t_te).to(device)\n",
    "\n",
    "Xtr_aux = torch.cat([A_tr.to(device), theta_tr], dim=1)  # shape [N,2]\n",
    "Xte_aux = torch.cat([A_te.to(device), theta_te], dim=1)\n",
    "\n",
    "kan_aux = KAN(\n",
    "    width=[2, 32, 1],  # input dim 2: (A, θ)\n",
    "    grid=5,\n",
    "    k=3,\n",
    "    seed=0,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset_aux = {\n",
    "    \"train_input\": Xtr_aux,\n",
    "    \"train_label\": y_tr,\n",
    "    \"test_input\":  Xte_aux,\n",
    "    \"test_label\":  y_te,\n",
    "}\n",
    "\n",
    "print(\"\\nTraining KAN with auxiliary θ = ω t ...\")\n",
    "kan_aux.fit(dataset_aux, opt=\"LBFGS\", steps=80, lamb=1e-6, lamb_l1=0.0, lamb_entropy=0.0, \n",
    "                update_grid=False,          # <--- add this\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_hat_aux = kan_aux(Xte_aux)\n",
    "\n",
    "kan_aux_rmse = rmse(y_te, y_hat_aux)\n",
    "kan_aux_r2   = r2_score_torch(y_te, y_hat_aux)\n",
    "\n",
    "print(\"\\n=== KAN (with θ = ω t) ===\")\n",
    "print(f\"RMSE: {kan_aux_rmse:.4f}\")\n",
    "print(f\"R²  : {kan_aux_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb6eee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.49e+00 | test_loss: 1.62e+00 | reg: 0.00e+00 | : 100%|█| 80/80 [00:59<00:00,  1.35it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "KAN (raw A, ω, t) — RMSE: 1.616328239440918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  A_tr, w_tr, t_tr, x_tr, A_te, w_te, t_te, x_te are defined\n",
    "\n",
    "Xtr_raw = torch.cat([A_tr, w_tr, t_tr], dim=1).to(device)\n",
    "Xte_raw = torch.cat([A_te, w_te, t_te], dim=1).to(device)\n",
    "\n",
    "kan_raw = KAN(width=[3, 32, 1], grid=5, k=3, seed=0, device=device)\n",
    "\n",
    "dataset_raw = {\n",
    "    \"train_input\": Xtr_raw,\n",
    "    \"train_label\": x_tr.to(device),\n",
    "    \"test_input\":  Xte_raw,\n",
    "    \"test_label\":  x_te.to(device),\n",
    "}\n",
    "\n",
    "#  update_grid=False \n",
    "kan_raw.fit(dataset_raw,\n",
    "            opt=\"LBFGS\",\n",
    "            steps=80,\n",
    "            lamb=0.0,\n",
    "            lamb_l1=0.0,\n",
    "            lamb_entropy=0.0,\n",
    "            update_grid=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_hat_raw = kan_raw(Xte_raw).cpu()\n",
    "\n",
    "rmse = torch.sqrt(torch.nn.MSELoss()(y_hat_raw, x_te))\n",
    "\n",
    "print(\"KAN (raw A, ω, t) — RMSE:\", rmse.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
